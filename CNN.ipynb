{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Convolutional Neural Network Simplified (Classification of Dog/Cat)**\n",
    "\n",
    "## **Goals of the project -**\n",
    "* To understand the basic implemetation of the CNN\n",
    "* To build the CNN layer by layer and understanding the significance of each layer and the arguments used\n",
    "* Performing operations like Convolutional, MaxPooling, Flatten, etc\n",
    "* Understanding the concepts of vector in Flattening and Full Connection\n",
    "* Implementing Image Augmentation operations like rescaling, horizontal flip on training and testing images \n",
    "* Using Image Data Generator for Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step - 1 :** Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QDivu_bSQmxz"
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from keras.models import Sequential     # initialize NN as a sequnce of layers\n",
    "from keras.layers import Convolution2D  # 2D coz it is an image not a video(3D) which has time stamp as well\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense          # to add fully connected layers\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')       # to ignore the warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.1 :** Intializing the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWgIsPdRQ5R8"
   },
   "outputs": [],
   "source": [
    "cnn_classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.2 :** Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2-FyF7AQ_2c"
   },
   "outputs": [],
   "source": [
    "cnn_classifier.add(Convolution2D(32, 3, 3, input_shape=(64, 64, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arguments used -**\n",
    "* `arg1` = no. of feature detectors or filters \n",
    "* `arg2` = no. of rows of each feature detector \n",
    "* `arg3` = no. of cols of each feature detector \n",
    "* `arg4` = input_shape, i.e the shape of the image. The goal is to force the shape of all images into the same format as the input images may be of different shape \n",
    "* `input_shape=(64, 64, 3)` says that the dim. will be 64x64 and 3 represents the 3 channel of RGB as it is a colored image \n",
    "* `activation='relu'` as classifying the image is a non-linear problem, we use rectifier to have non-linearity in our model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.3 :** Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-8sw1R6RD2V"
   },
   "outputs": [],
   "source": [
    "cnn_classifier.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Argument used -**\n",
    "* `pool_size` represents the size of pooling image, usually kept 2x2 to not lose info and be precise as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cS2A7GWSRFeH"
   },
   "outputs": [],
   "source": [
    "# adding 2d layer for better accuracy(not added coz of hardware limitations)\n",
    "# cnn_classifier.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "# cnn_classifier.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.4 :** Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2w8poNk1RIaN"
   },
   "outputs": [],
   "source": [
    "cnn_classifier.add(Flatten())  # to create a vector of pooling image having a unique feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.5 :** Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JO1L-xzJRLMx"
   },
   "outputs": [],
   "source": [
    "cnn_classifier.add(Dense(output_dim=128, activation='relu'))   # input layer\n",
    "cnn_classifier.add(Dense(output_dim=1, activation='sigmoid'))  # output layer (1 coz we need to predict a dog or a cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.5 :** Compile(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCIm0ZFmRNBC"
   },
   "outputs": [],
   "source": [
    "cnn_classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arguments used -**\n",
    "\n",
    "* `optimizer` = name of the algorithm we want to apply, usually SGD algorithm known by 'adam'\n",
    "* `loss` = it is a loss function within SGD algorithm, or the function we need to optimize to find optimal weights usually based on the activation function used for the o/p layer, or the type of dependent variable\n",
    "* `metrics` parameter has [ ] coz it expects a list of values as the weights have been calculated after each observation or each batch of observations. Hence the algorithm uses this parameter to calculate the accuracy to improve the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step - 2 : Fitting CNN to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gQgxDRJOROuG"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note -**\n",
    "Following is a template taken from Keras Documentation for Image preprocessing and fitting the model by taking the data from a directory\n",
    "\n",
    "**Step 2.1 :** Image Augmentation\n",
    "* Rescaling the Training data\n",
    "* This step is necessary as it generates many transformations so that we don't find same image in different batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vnmuk8ruRQQe"
   },
   "outputs": [],
   "source": [
    "# creating the function\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,                      \n",
    "    shear_range=0.2,                       \n",
    "    zoom_range=0.2,                         \n",
    "    horizontal_flip=True)                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arguments used -**\n",
    "* `rescale` rescales all pixel values between 0 and 1\n",
    "* `shear_range` performs random transvection (0.2) suggested by keras i.e. A kind of linear mapping which leaves all points on one axis fixed, while other points are shifted parallel to the axis by a distance proportional to their perpendicular distance from the axis\n",
    "* `zoom_range` is random zoom (0.2) suggested by keras\n",
    "* `horizontal_flip=True` images will be flipped horizontally\n",
    "\n",
    "**Step 2.2 :** Rescaling the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LnKUoNi7RTxG"
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.3 :** Applying image augmentation on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "avsc-UpdRVrG",
    "outputId": "9dbe40e4-8490-4f97-d35d-0e48771e5aac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('C:/Users/Rohit/Desktop/Data Science/Deep Learning/Datasets/training_set',\n",
    "                                              target_size=(64, 64), batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arguments used -**\n",
    "* `target_size` size of images expected in the cnn model, same as the input shape\n",
    "* `batch_size` size of the batches where random samples of image will be included \n",
    "or after how many inputs the weights will be updated\n",
    "* `class_mode` = 'binary' as this is a classification problem (2 classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.4 :** Applying image augmentation on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gcyE08ldeklY",
    "outputId": "f6d3720f-c26d-478c-bce0-df7b222d374a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('C:/Users/Rohit/Desktop/Data Science/Deep Learning/Datasets/test_set',\n",
    "                                            target_size=(64, 64), batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.5 :** Fitting the model\n",
    "\n",
    "**Arguments used -** \n",
    "* `steps_per_epoch` - no. of images in training set\n",
    "* `validation_steps` - no. of images in testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "S0SdV-3NhYMd",
    "outputId": "01db34a3-adcb-4fc5-d019-04f0b486f6b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 2277s 285ms/step - loss: 0.3312 - accuracy: 0.8528 - val_loss: 0.5600 - val_accuracy: 0.7568\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 2410s 301ms/step - loss: 0.2459 - accuracy: 0.8958 - val_loss: 0.7867 - val_accuracy: 0.7609\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 2209s 276ms/step - loss: 0.1911 - accuracy: 0.9219 - val_loss: 0.7684 - val_accuracy: 0.7471\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 2154s 269ms/step - loss: 0.1555 - accuracy: 0.9386 - val_loss: 1.6236 - val_accuracy: 0.7574\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1936s 242ms/step - loss: 0.1308 - accuracy: 0.9499 - val_loss: 1.3602 - val_accuracy: 0.7399\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1938s 242ms/step - loss: 0.1122 - accuracy: 0.9582 - val_loss: 2.0356 - val_accuracy: 0.7464\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1936s 242ms/step - loss: 0.0962 - accuracy: 0.9649 - val_loss: 2.4215 - val_accuracy: 0.7520\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1932s 241ms/step - loss: 0.0841 - accuracy: 0.9698 - val_loss: 1.4613 - val_accuracy: 0.7464\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1942s 243ms/step - loss: 0.0773 - accuracy: 0.9721 - val_loss: 2.4890 - val_accuracy: 0.7394\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1940s 242ms/step - loss: 0.0685 - accuracy: 0.9756 - val_loss: 2.8670 - val_accuracy: 0.7438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x15f3273e2c8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_classifier.fit(training_set, steps_per_epoch=8000, epochs=10, validation_data=test_set, validation_steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step - 3 : Making New Prediction\n",
    "\n",
    "* Here we will pass an image of a dog to see if our CNN identifies it correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.1 :** Pre-processing the image which we are going to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxIhV2Tuhbcf"
   },
   "outputs": [],
   "source": [
    "import numpy as np    # to pre-process the image so that it gets accepted by predict method we are going to use\n",
    "from keras.preprocessing import image   # to load the image\n",
    "\n",
    "# the loaded image goes here\n",
    "test_image = image.load_img('C:/Users/Rohit/Desktop/Data Science/Deep Learning/Datasets/single_prediction/dog.jpg',\n",
    "                            target_size=(64, 64))   # target size same as that of the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x15F317D0348>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pH7YAYVoWos-"
   },
   "source": [
    "**Step 3.2 :** Changing the dimensions of the test image from 64x64(2D) to 64x64x3(3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6hXoV3kZ4eCp"
   },
   "outputs": [],
   "source": [
    "test_image = image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.3 :** Changing the above image to 4 dimension\n",
    "* The predict method expects 4 dimensions and we have only 3\n",
    "* It can't take a single input i.e image\n",
    "* It only accepts inputs in a batch\n",
    "* Hence the 4th dimension is the batch, even if the batch has 1 input, the inputs must be in a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.4 :** Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "result = cnn_classifier.predict(test_image)\n",
    "print(result) # to check the result\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.5 :** Checking the indices\n",
    "* We don't know from the result obtained above whether 1 stands for cat or a dog\n",
    "* Hence we use the attribute called `class_indices`, which gives us the info about the index assigned to each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mnKjbu1Ajjez"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result tells us that it identified the **dog** correctly\n",
    "\n",
    "**Step 3.6 :** Additional step **(Making result more explanatory)**\n",
    "* We extract the 1st element from `result` as it is a 2d array to identify whether the image is of a cat or a dog\n",
    "* Then we assign them with their respective class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CNN identified the newly loaded image as Dog\n"
     ]
    }
   ],
   "source": [
    "if result[0][0] == 1:\n",
    "    prediction = 'Dog'\n",
    "else:\n",
    "    prediction = 'Cat'\n",
    "    \n",
    "# printing the result\n",
    "print(f\"The CNN identified the newly loaded image as {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
