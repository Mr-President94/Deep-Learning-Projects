{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Convolutional Neural Network Simplified (Dog/Cat Recognition)**\n",
    "\n",
    "## **Goals of the project -**\n",
    "* To understand the basic implemetation of the CNN\n",
    "* To build the CNN layer by layer and understanding the significance of each layer and the arguments used\n",
    "* Performing operations like Convolutional, MaxPooling, Flatten, etc\n",
    "* Understanding the concepts of vector in Flattening and Full Connection\n",
    "* Implementing Image Augmentation operations like rescaling, horizontal flip on training and testing images \n",
    "* Using Image Data Generator for Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step - 1 :** Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QDivu_bSQmxz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "from keras.models import Sequential     # initialize NN as a sequnce of layers\n",
    "from keras.layers import Convolution2D  # 2D coz it is an image not a video(3D) which has time stamp as well\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense          # to add fully connected layers\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')       # to ignore the warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.1 :** Intializing the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWgIsPdRQ5R8"
   },
   "outputs": [],
   "source": [
    "cnn_classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.2 :** Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2-FyF7AQ_2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sragh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "cnn_classifier.add(Convolution2D(32, 3, 3, input_shape=(64, 64, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arguments used -**\n",
    "* `arg1` = no. of feature detectors or filters \n",
    "* `arg2` = no. of rows of each feature detector \n",
    "* `arg3` = no. of cols of each feature detector \n",
    "* `arg4` = input_shape, i.e the shape of the image. The goal is to force the shape of all images into the same format as the input images may be of different shape \n",
    "* `input_shape=(64, 64, 3)` says that the dim. will be 64x64 and 3 represents the 3 channel of RGB as it is a colored image \n",
    "* `activation='relu'` as classifying the image is a non-linear problem, we use rectifier to have non-linearity in our model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.3 :** Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-8sw1R6RD2V"
   },
   "outputs": [],
   "source": [
    "cnn_classifier.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Argument used -**\n",
    "* `pool_size` represents the size of pooling image, usually kept 2x2 to not lose info and be precise as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cS2A7GWSRFeH"
   },
   "outputs": [],
   "source": [
    "# adding 2d layer for better accuracy(not added coz of hardware limitations)\n",
    "# cnn_classifier.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "# cnn_classifier.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.4 :** Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2w8poNk1RIaN"
   },
   "outputs": [],
   "source": [
    "cnn_classifier.add(Flatten())  # to create a vector of pooling image having a unique feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.5 :** Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JO1L-xzJRLMx"
   },
   "outputs": [],
   "source": [
    "cnn_classifier.add(Dense(output_dim=128, activation='relu'))   # input layer\n",
    "cnn_classifier.add(Dense(output_dim=1, activation='sigmoid'))  # output layer (1 coz we need to predict a dog or a cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.5 :** Compile(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCIm0ZFmRNBC"
   },
   "outputs": [],
   "source": [
    "cnn_classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arguments used -**\n",
    "\n",
    "* `optimizer` = name of the algorithm we want to apply, usually SGD algorithm known by 'adam'\n",
    "* `loss` = it is a loss function within SGD algorithm, or the function we need to optimize to find optimal weights usually based on the activation function used for the o/p layer, or the type of dependent variable\n",
    "* `metrics` parameter has [ ] coz it expects a list of values as the weights have been calculated after each observation or each batch of observations. Hence the algorithm uses this parameter to calculate the accuracy to improve the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step - 2 : Fitting CNN to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gQgxDRJOROuG"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note -**\n",
    "Following is a template taken from Keras Documentation for Image preprocessing and fitting the model by taking the data from a directory\n",
    "\n",
    "**Step 2.1 :** Image Augmentation\n",
    "* Rescaling the Training data\n",
    "* This step is necessary as it generates many transformations so that we don't find same image in different batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vnmuk8ruRQQe"
   },
   "outputs": [],
   "source": [
    "# creating the function\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,                      \n",
    "    shear_range=0.2,                       \n",
    "    zoom_range=0.2,                         \n",
    "    horizontal_flip=True)                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arguments used -**\n",
    "* `rescale` rescales all pixel values between 0 and 1\n",
    "* `shear_range` performs random transvection (0.2) suggested by keras i.e. A kind of linear mapping which leaves all points on one axis fixed, while other points are shifted parallel to the axis by a distance proportional to their perpendicular distance from the axis\n",
    "* `zoom_range` is random zoom (0.2) suggested by keras\n",
    "* `horizontal_flip=True` images will be flipped horizontally\n",
    "\n",
    "**Step 2.2 :** Rescaling the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LnKUoNi7RTxG"
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.3 :** Applying image augmentation on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "avsc-UpdRVrG",
    "outputId": "9dbe40e4-8490-4f97-d35d-0e48771e5aac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('C:/Users/Rohit/Desktop/Data Science/Deep Learning/Datasets/training_set',\n",
    "                                              target_size=(64, 64), batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arguments used -**\n",
    "* `target_size` size of images expected in the cnn model, same as the input shape\n",
    "* `batch_size` size of the batches where random samples of image will be included \n",
    "or after how many inputs the weights will be updated\n",
    "* `class_mode` = 'binary' as this is a classification problem (2 classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.4 :** Applying image augmentation on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gcyE08ldeklY",
    "outputId": "f6d3720f-c26d-478c-bce0-df7b222d374a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('C:/Users/Rohit/Desktop/Data Science/Deep Learning/Datasets/test_set',\n",
    "                                            target_size=(64, 64), batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.5 :** Fitting the model\n",
    "\n",
    "**Arguments used -** \n",
    "* `steps_per_epoch` - no. of images in training set\n",
    "* `validation_steps` - no. of images in testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "S0SdV-3NhYMd",
    "outputId": "01db34a3-adcb-4fc5-d019-04f0b486f6b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sragh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 2123s 265ms/step - loss: 0.4004 - accuracy: 0.8092 - val_loss: 1.1346 - val_accuracy: 0.7547\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 1932s 241ms/step - loss: 0.1666 - accuracy: 0.9337 - val_loss: 0.8074 - val_accuracy: 0.7469\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 1983s 248ms/step - loss: 0.0921 - accuracy: 0.9658 - val_loss: 0.8953 - val_accuracy: 0.7605\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 1908s 238ms/step - loss: 0.0636 - accuracy: 0.9776 - val_loss: 1.0257 - val_accuracy: 0.7534\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 1796s 224ms/step - loss: 0.0511 - accuracy: 0.9825 - val_loss: 2.1484 - val_accuracy: 0.7483\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 1795s 224ms/step - loss: 0.0405 - accuracy: 0.9864 - val_loss: 1.4349 - val_accuracy: 0.7636\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 1743s 218ms/step - loss: 0.0353 - accuracy: 0.9885 - val_loss: 1.0907 - val_accuracy: 0.7503\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 1825s 228ms/step - loss: 0.0299 - accuracy: 0.9902 - val_loss: 3.1207 - val_accuracy: 0.7669\n",
      "Epoch 9/25\n",
      "8000/8000 [==============================] - 1832s 229ms/step - loss: 0.0278 - accuracy: 0.9914 - val_loss: 0.7866 - val_accuracy: 0.7590\n",
      "Epoch 10/25\n",
      "8000/8000 [==============================] - 1849s 231ms/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 1.2831 - val_accuracy: 0.7483\n",
      "Epoch 11/25\n",
      "8000/8000 [==============================] - 2549s 319ms/step - loss: 0.0212 - accuracy: 0.9932 - val_loss: 2.8772 - val_accuracy: 0.7669\n",
      "Epoch 12/25\n",
      "8000/8000 [==============================] - 2729s 341ms/step - loss: 0.0212 - accuracy: 0.9935 - val_loss: 2.6700 - val_accuracy: 0.7655\n",
      "Epoch 13/25\n",
      "8000/8000 [==============================] - 2579s 322ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.7723 - val_accuracy: 0.7571\n",
      "Epoch 14/25\n",
      "8000/8000 [==============================] - 2886s 361ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 1.2392 - val_accuracy: 0.7704\n",
      "Epoch 15/25\n",
      "8000/8000 [==============================] - 1812s 226ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 1.6090 - val_accuracy: 0.7482\n",
      "Epoch 16/25\n",
      "8000/8000 [==============================] - 1672s 209ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 1.3965 - val_accuracy: 0.7619\n",
      "Epoch 17/25\n",
      "8000/8000 [==============================] - 1667s 208ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.8658 - val_accuracy: 0.7639\n",
      "Epoch 18/25\n",
      "8000/8000 [==============================] - 1672s 209ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.5117 - val_accuracy: 0.7583\n",
      "Epoch 19/25\n",
      "8000/8000 [==============================] - 1664s 208ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.9701 - val_accuracy: 0.7697\n",
      "Epoch 20/25\n",
      "8000/8000 [==============================] - 1668s 208ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 1.7570 - val_accuracy: 0.7665\n",
      "Epoch 21/25\n",
      "8000/8000 [==============================] - 1661s 208ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 1.2972 - val_accuracy: 0.7665\n",
      "Epoch 22/25\n",
      "8000/8000 [==============================] - 1673s 209ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 2.1569 - val_accuracy: 0.7635\n",
      "Epoch 23/25\n",
      "8000/8000 [==============================] - 1682s 210ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 2.7047 - val_accuracy: 0.7643\n",
      "Epoch 24/25\n",
      "8000/8000 [==============================] - 1701s 213ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 2.0364 - val_accuracy: 0.7567\n",
      "Epoch 25/25\n",
      "8000/8000 [==============================] - 1716s 214ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 2.5504 - val_accuracy: 0.7589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f9b2317388>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_classifier.fit(training_set, steps_per_epoch=8000, epochs=25, validation_data=test_set, validation_steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step - 3 : Making New Prediction\n",
    "\n",
    "* Here we will pass an image of a dog to see if our CNN identifies it correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.1 :** Pre-processing the image which we are going to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxIhV2Tuhbcf"
   },
   "outputs": [],
   "source": [
    "import numpy as np    # to pre-process the image so that it gets accepted by predict method we are going to use\n",
    "from keras.preprocessing import image   # to load the image\n",
    "\n",
    "# the loaded image goes here\n",
    "test_image = image.load_img('C:/Users/Rohit/Desktop/Data Science/Deep Learning/Datasets/single_prediction/dog.jpg',\n",
    "                            target_size=(64, 64))   # target size same as that of the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x1876BDDF388>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pH7YAYVoWos-"
   },
   "source": [
    "**Step 3.2 :** Changing the dimensions of the test image from 64x64(2D) to 64x64x3(3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6hXoV3kZ4eCp"
   },
   "outputs": [],
   "source": [
    "test_image = image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.3 :** Changing the above image to 4 dimension\n",
    "* The predict method expects 4 dimensions and we have only 3\n",
    "* It can't take a single input i.e image\n",
    "* It only accepts inputs in a batch\n",
    "* Hence the 4th dimension is the batch, even if the batch has 1 input, the inputs must be in a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.4 :** Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "result = cnn_classifier.predict(test_image)\n",
    "print(result) # to check the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.5 :** Checking the indices\n",
    "* We don't know from the result obtained above whether 1 stands for cat or a dog\n",
    "* Hence we use the attribute called `class_indices`, which gives us the info about the index assigned to each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mnKjbu1Ajjez"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result tells us that it identified the **dog** correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.6 :** Additional step **(Making result more explanatory)**\n",
    "* We extract the 1st element from `result` as it is a 2d array to identify whether the image is of a cat or a dog\n",
    "* Then we assign them with their respective class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CNN identified the newly loaded image as Dog\n"
     ]
    }
   ],
   "source": [
    "if result[0][0] == 1:\n",
    "    prediction = 'Dog'\n",
    "else:\n",
    "    prediction = 'Cat'\n",
    "    \n",
    "# printing the result\n",
    "print(f\"The CNN identified the newly loaded image as {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking whether it identifies the **cat** as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x1876C2DC1C8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image2 = image.load_img('C:/Users/Rohit/Desktop/Data Science/Deep Learning/Datasets/single_prediction/cat.jpg',\n",
    "                            target_size=(64, 64))\n",
    "test_image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CNN identified the newly loaded image as Cat\n"
     ]
    }
   ],
   "source": [
    "test_image2 = image.img_to_array(test_image2)\n",
    "test_image2 = np.expand_dims(test_image2, axis=0)\n",
    "result2 = cnn_classifier.predict(test_image2)\n",
    "\n",
    "if result2[0][0] == 1:\n",
    "    prediction2 = 'Dog'\n",
    "else:\n",
    "    prediction2 = 'Cat'\n",
    "\n",
    "print(f\"The CNN identified the newly loaded image as {prediction2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
